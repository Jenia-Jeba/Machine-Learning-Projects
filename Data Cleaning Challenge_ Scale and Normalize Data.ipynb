{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# for Box-Cox Transformation\nfrom scipy import stats\n\n# for min_max scaling\nfrom mlxtend.preprocessing import minmax_scaling\n\n# plotting modules\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# read in all our data\nkickstarters_2017 = pd.read_csv(\"../input/kickstarter-projects/ks-projects-201801.csv\")\n\n# set seed for reproducibility\nnp.random.seed(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Scaling**\n\nThis means that you're transforming your data so that it fits within a specific scale, like 0-100 or 0-1. You want to scale data when you're using methods based on measures of how far apart data points, like support vector machines, or SVM or k-nearest neighbors, or KNN. With these algorithms, a change of \"1\" in any numeric feature is given the same importance.\n\nFor example, you might be looking at the prices of some products in both Yen and US Dollars. One US Dollar is worth about 100 Yen, but if you don't scale your prices methods like SVM or KNN will consider a difference in price of 1 Yen as important as a difference of 1 US Dollar! This clearly doesn't fit with our intuitions of the world. With currency, you can convert between currencies. But what about if you're looking at something like height and weight? It's not entirely clear how many pounds should equal one inch (or how many kilograms should equal one meter).\n\nBy scaling your variables, you can help compare different variables on equal footing. To help solidify what scaling looks like, let's look at a made-up example. (Don't worry, we'll work with real data in just a second, this is just to help illustrate my point.)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate 1000 data points randomly drawn from an exponential distribution\noriginal_data = np.random.exponential(size = 1000)\n\n# mix-max scale the data between 0 and 1\nscaled_data = minmax_scaling(original_data, columns = [0])\n\n# plot both together to compare\n\nfig, ax=plt.subplots(1,2)\n\nsns.distplot(original_data, ax=ax[0])\nax[0].set_title(\"Original Data\")\n\nsns.distplot(scaled_data, ax=ax[1])\nax[1].set_title(\"Scaled data\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that the shape of the data doesn't change, but that instead of ranging from 0 to 8ish, it now ranges from 0 to 1.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Normalization**\n\nScaling just changes the range of your data. Normalization is a more radical transformation. The point of normalization is to change your observations so that they can be described as a normal distribution.\n\nNormal distribution: Also known as the \"bell curve\", this is a specific statistical distribution where a roughly equal observations fall above and below the mean, the mean and the median are the same, and there are more observations closer to the mean. The normal distribution is also known as the Gaussian distribution.\n\nIn general, you'll only want to normalize your data if you're going to be using a machine learning or statistics technique that assumes your data is normally distributed. Some examples of these include t-tests, ANOVAs, linear regression, linear discriminant analysis (LDA) and Gaussian naive Bayes. (Pro tip: any method with \"Gaussian\" in the name probably assumes normality.)\n\n> The method were using to normalize here is called the Box-Cox Transformation. Let's take a quick peek at what normalizing some data looks like:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize the exponential data with boxcox\nnormalized_data = stats.boxcox(original_data)\n\n# plot both together to compare\nfig, ax=plt.subplots(1,2)\n\nsns.distplot(original_data, ax=ax[0])\nax[0].set_title(\"Original Data\")\n\nsns.distplot(normalized_data[0], ax=ax[1])\nax[1].set_title(\"Normalized data\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that the shape of our data has changed. Before normalizing it was almost L-shaped. But after normalizing it looks more like the outline of a bell (hence \"bell curve\").\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# select the usd_goal_real column\nusd_goal = kickstarters_2017.usd_goal_real\n\n# scale the goals from 0 to 1\nscaled_data = minmax_scaling(usd_goal, columns = [0])\n\n# plot the original & scaled data together to compare\nfig, ax=plt.subplots(1,2)\nsns.distplot(kickstarters_2017.usd_goal_real, ax=ax[0])\nax[0].set_title(\"Original Data\")\nsns.distplot(scaled_data, ax=ax[1])\nax[1].set_title(\"Scaled data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the index of all positive pledges (Box-Cox only takes postive values)\nindex_of_positive_pledges = kickstarters_2017.usd_pledged_real > 0\n\n# get only positive pledges (using their indexes)\npositive_pledges = kickstarters_2017.usd_pledged_real.loc[index_of_positive_pledges]\n\n# normalize the pledges (w/ Box-Cox)\nnormalized_pledges = stats.boxcox(positive_pledges)[0]\n\n# plot both together to compare\nfig, ax=plt.subplots(1,2)\nsns.distplot(positive_pledges, ax=ax[0])\nax[0].set_title(\"Original Data\")\nsns.distplot(normalized_pledges, ax=ax[1])\nax[1].set_title(\"Normalized data\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}